# Data Engineer Study Plan ğŸ“Š

Um plano de estudos completo para Engenharia de Dados, focado em Apache Spark, PySpark e SQL.

## ğŸ“ Estrutura do Projeto

```
DataEngineer-StudyPlan/
â”œâ”€â”€ 01-conceitos/              # Fundamentos teÃ³ricos
â”‚   â”œâ”€â”€ spark_conceitos_fundamentais.md
â”‚   â””â”€â”€ sql_conceitos_fundamentais.md
â”œâ”€â”€ 02-guias-praticos/         # Guias prÃ¡ticos com exemplos
â”‚   â”œâ”€â”€ pyspark_guia_pratico.md
â”‚   â””â”€â”€ sql_guia_pratico.md
â”œâ”€â”€ 03-exercicios/             # ExercÃ­cios prÃ¡ticos e gabaritos
â”‚   â”œâ”€â”€ exercicios_pyspark.md
â”‚   â”œâ”€â”€ exercicios_sql.md
â”‚   â”œâ”€â”€ gabarito_pyspark.md
â”‚   â””â”€â”€ gabarito_sql.md
â”œâ”€â”€ 04-dados/                  # Datasets para exercÃ­cios
â”‚   â”œâ”€â”€ vendas.csv
â”‚   â”œâ”€â”€ funcionarios.csv
â”‚   â”œâ”€â”€ clientes.csv
â”‚   â”œâ”€â”€ produtos.csv
â”‚   â””â”€â”€ criar_tabelas.sql
â””â”€â”€ README.md
```

## ğŸ¯ Objetivos do Plano de Estudos

Este repositÃ³rio foi criado para fornecer um caminho estruturado de aprendizado em Engenharia de Dados, cobrindo:

- **Fundamentos teÃ³ricos** sÃ³lidos em Spark e SQL
- **Exemplos prÃ¡ticos** executÃ¡veis
- **ExercÃ­cios progressivos** (bÃ¡sico â†’ intermediÃ¡rio â†’ avanÃ§ado)
- **Datasets reais** para prÃ¡tica
- **Gabaritos detalhados** com explicaÃ§Ãµes

## ğŸ“š ConteÃºdo Detalhado

### 01 - Conceitos Fundamentais

#### ğŸ”¥ Spark Conceitos Fundamentais
- Arquitetura do Spark (Driver, Executors, Cluster Manager)
- RDDs, DataFrames e Datasets
- Lazy Evaluation e DAG
- Particionamento e Shuffling
- Catalyst Optimizer
- Spark UI e Monitoramento
- Cache e PersistÃªncia
- Formatos de arquivo (Parquet, ORC, Delta, Iceberg)

#### ğŸ—ƒï¸ SQL Conceitos Fundamentais
- Modelo Relacional e NormalizaÃ§Ã£o
- Ãlgebra Relacional
- Arquitetura de SGBD
- Processamento e OtimizaÃ§Ã£o de Consultas
- Ãndices e Performance
- TransaÃ§Ãµes ACID
- Data Warehousing e OLAP
- SeguranÃ§a e Auditoria

### 02 - Guias PrÃ¡ticos

#### âš¡ PySpark Guia PrÃ¡tico
- ConfiguraÃ§Ã£o do ambiente
- OperaÃ§Ãµes bÃ¡sicas com DataFrames
- TransformaÃ§Ãµes e AÃ§Ãµes
- Window Functions
- Joins e AgregaÃ§Ãµes
- UDFs (User Defined Functions)
- Streaming e Machine Learning
- OtimizaÃ§Ã£o de Performance

#### ğŸ“Š SQL Guia PrÃ¡tico
- Consultas bÃ¡sicas e avanÃ§adas
- JOINs e Subconsultas
- Window Functions e CTEs
- FunÃ§Ãµes de agregaÃ§Ã£o
- ManipulaÃ§Ã£o de strings e datas
- Ãndices e otimizaÃ§Ã£o
- TransaÃ§Ãµes e controle de concorrÃªncia

### 03 - ExercÃ­cios PrÃ¡ticos

#### NÃ­veis de Dificuldade:

**ğŸŸ¢ BÃ¡sico**
- OperaÃ§Ãµes fundamentais
- Filtros e agregaÃ§Ãµes simples
- JOINs bÃ¡sicos

**ğŸŸ¡ IntermediÃ¡rio**
- Window Functions
- AnÃ¡lises temporais
- TransformaÃ§Ãµes complexas
- OtimizaÃ§Ã£o de queries

**ğŸ”´ AvanÃ§ado**
- Machine Learning
- Sistemas de recomendaÃ§Ã£o
- Data Warehousing
- ETL complexo
- AnÃ¡lise preditiva

### 04 - Dados para PrÃ¡tica

**Datasets incluÃ­dos:**
- `vendas.csv` - Dados de vendas (20 registros)
- `funcionarios.csv` - Dados de funcionÃ¡rios (10 registros)
- `clientes.csv` - Dados de clientes (15 registros)
- `produtos.csv` - Dados de produtos (12 registros)
- `criar_tabelas.sql` - Script para criar tabelas SQL

## ğŸš€ Como Usar Este RepositÃ³rio

### 1. **Estude os Conceitos**
```bash
# Comece pelos fundamentos
cat 01-conceitos/spark_conceitos_fundamentais.md
cat 01-conceitos/sql_conceitos_fundamentais.md
```

### 2. **Pratique com os Guias**
```bash
# Execute os exemplos prÃ¡ticos
cat 02-guias-praticos/pyspark_guia_pratico.md
cat 02-guias-praticos/sql_guia_pratico.md
```

### 3. **Resolva os ExercÃ­cios**
```bash
# Tente resolver antes de ver o gabarito
cat 03-exercicios/exercicios_pyspark.md
cat 03-exercicios/exercicios_sql.md
```

### 4. **Configure o Ambiente**

#### Para PySpark:
```bash
# Instalar dependÃªncias
pip install pyspark pandas numpy matplotlib seaborn

# Iniciar PySpark
pyspark
```

#### Para SQL:
```bash
# Executar script de criaÃ§Ã£o das tabelas
psql -d seu_banco -f 04-dados/criar_tabelas.sql
```

## ğŸ› ï¸ PrÃ©-requisitos

- **Python 3.7+**
- **Apache Spark 3.0+**
- **PostgreSQL** (para exercÃ­cios SQL)
- **Jupyter Notebook** (recomendado)

### InstalaÃ§Ã£o RÃ¡pida:
```bash
# Instalar PySpark
pip install pyspark

# Instalar PostgreSQL (macOS)
brew install postgresql

# Instalar Jupyter
pip install jupyter
```

## ğŸ“ˆ ProgressÃ£o Sugerida

1. **Semana 1-2**: Conceitos fundamentais do Spark
2. **Semana 3-4**: Conceitos fundamentais de SQL
3. **Semana 5-6**: Guias prÃ¡ticos (PySpark + SQL)
4. **Semana 7-8**: ExercÃ­cios bÃ¡sicos
5. **Semana 9-10**: ExercÃ­cios intermediÃ¡rios
6. **Semana 11-12**: ExercÃ­cios avanÃ§ados

## ğŸ¯ Objetivos de Aprendizado

Ao completar este plano de estudos, vocÃª serÃ¡ capaz de:

- âœ… Compreender a arquitetura do Apache Spark
- âœ… Desenvolver aplicaÃ§Ãµes PySpark eficientes
- âœ… Escrever queries SQL complexas e otimizadas
- âœ… Implementar pipelines de ETL
- âœ… Otimizar performance de aplicaÃ§Ãµes de dados
- âœ… Trabalhar com diferentes formatos de arquivo
- âœ… Implementar soluÃ§Ãµes de Machine Learning
- âœ… Projetar Data Warehouses dimensionais

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para:

- Reportar bugs ou erros
- Sugerir melhorias
- Adicionar novos exercÃ­cios
- Melhorar a documentaÃ§Ã£o

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo LICENSE para mais detalhes.

## ğŸ“ Contato

Para dÃºvidas ou sugestÃµes:
- GitHub: [@bruno708](https://github.com/bruno708)
- Email: [seu-email@exemplo.com]

---

**Happy Learning! ğŸš€ğŸ“Š**

> "A jornada de mil milhas comeÃ§a com um Ãºnico passo" - Lao Tzu

Comece sua jornada em Engenharia de Dados hoje mesmo! ğŸ’ª